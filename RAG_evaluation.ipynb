{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r0/9515969s651bj983pxgsbgyc0000gn/T/ipykernel_96925/2099715118.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"custom.css\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<link rel=\"stylesheet\" type=\"text/css\" href=\"custom.css\">'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start evaluating my chat assistant's question answering ability. Below are the validations I'm planning.\n",
    "1. Is the answer relevant to the question?\n",
    "2. Is the answer has all the important points taken from my resume relevant to the question asked?\n",
    "3. Are the contexts retrieved from vector db is the most matched chunks with my question?\n",
    "4. Is the answer relevant to the context ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially I tried with [Non-LLM Evaluation techniques](#non_llm_evaluations). Later, I used [LLM Evaluation techniques](#llm_evaluations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting response from the RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are A CHAT ASSISTANT even with or without context and you are NOT Haripriya. You are supposed to answer the questions asked only about Haripriya and you are NOT Haripriya. Use the following pieces of retrieved context to answer the question.\n",
      "\n",
      "new  data  provider  for  classifying  the  customer’s  industry  type,  after  analysing  the  data  during  COVID-19  \n",
      "Pandemic\n",
      " \n",
      "in\n",
      " \n",
      "order\n",
      " \n",
      "to\n",
      " \n",
      "decide\n",
      " \n",
      "based\n",
      " \n",
      "on\n",
      " \n",
      "the\n",
      " \n",
      "recession\n",
      " \n",
      "in\n",
      " \n",
      "particular\n",
      " \n",
      "industry\n",
      " \n",
      "type.\n",
      " ●  Actively  participated  in  all  hackathons  and  innovation  days  conducted  by  ADF  (BERT  algorithm  for  NLP  \n",
      "using\n",
      " \n",
      "Kaggle\n",
      " \n",
      "platform,\n",
      " \n",
      "a\n",
      " \n",
      "new\n",
      " \n",
      "version\n",
      " \n",
      "of\n",
      " \n",
      "Dependent\n",
      " \n",
      "variable\n",
      " \n",
      "for\n",
      " \n",
      "the\n",
      " \n",
      "risk\n",
      " \n",
      "models).\n",
      " ●  Worked  on  migrating  the  models  to  updated  python  version  and  optimising  the  existing  models.  \n",
      "MQ  Spectrum  Pte  Ltd,  Chennai  — \n",
      "Assistant  Technical  Lead  and  SDE  II   –  Oct  2017  -  Aug  2019\n",
      " Worked  in  Liferay  Platform,  Apache  Tomcat  Web  application  with  Java,  J2EE,  ASP.NET,  WPF   and  Search  Indexer  \n",
      "in\n",
      " \n",
      "C#,\n",
      " \n",
      "Moodle\n",
      " \n",
      "framework\n",
      " \n",
      "and\n",
      " \n",
      "SQL\n",
      " \n",
      "Server.\n",
      " \n",
      "AWARDS\n",
      " ●  A  special  appreciation  post  on  company’s  LinkedIn page.  ●  SECOND prize  in  ADF’s  Data  science  hackathon  and  a  Special  award  in  Technology  Hackathon.  ●  ADF  Excellence  Award from  ADF  for  my  dedicated  work.  ●  DISTRICT  FIRST  in  Sri  Ramanujan  Maths  aptitude  test  and  SECOND  in  Maths  Quiz  during  my  HSC.  ●  School  First  in  academics  in  both  SSLC  and  Higher  secondary  school  receiving  97%  of  marks. \n",
      "LINKS\n",
      "\n",
      "●  Programming  for  Everybody  (Python)-  U-M  -  Coursera  Certificate  :  https://coursera.org/share/82e42e01b306f5a268181bb5267246c1 ●  MITx  Micromasters:  https://micromasters.mit.edu/ds/ ●  Kaggle  Page  :  https://www.kaggle.com/haripriya04raj ●  MachineHack  :  https://machinehack.com/user/5ef0a238b7efcc325e3907d1 ●  Case  Study  in  RPubs:  https://rpubs.com/haripriya_rhp/cyclistic-case-study ●  Case  Study  in  GitHub  :  https://github.com/hari04hp/google-advanced-capstone\n",
      "\n",
      "fine-tuning\n",
      " \n",
      "makes\n",
      " \n",
      "an\n",
      " \n",
      "impact\n",
      " \n",
      "and\n",
      " \n",
      "how\n",
      " \n",
      "well\n",
      " \n",
      "the\n",
      " \n",
      "hyperparameter\n",
      " \n",
      "tuning\n",
      "  \n",
      "affects\n",
      " \n",
      "the\n",
      " \n",
      "response.\n",
      " \n",
      "I\n",
      " \n",
      "tried\n",
      " \n",
      "various\n",
      " hyperparameters,  inferred  the  response  and  created  a  notebook  with  it.  It  is  located  in  github.   PORTFOLIO  WEBSITE  AND  A  CHAT  ASSISTANT  WITH  RAG  USING  LANGCHAIN As  a  personal  project,  I  developed  my  portfolio  website  with  streamlit  incorporating  a  chat  interface  using  \n",
      "GenerativeAI\n",
      " \n",
      "using\n",
      " \n",
      "LangChain\n",
      " \n",
      "with\n",
      " \n",
      "my\n",
      " \n",
      "resume\n",
      " \n",
      "embedded.\n",
      " \n",
      "It\n",
      " \n",
      "can\n",
      " \n",
      "give\n",
      " \n",
      "a\n",
      " \n",
      "summary\n",
      " \n",
      "and\n",
      " \n",
      "can\n",
      " \n",
      "answer\n",
      " \n",
      "various\n",
      " \n",
      "questions\n",
      " \n",
      "about\n",
      " \n",
      "me\n",
      " \n",
      "with\n",
      " \n",
      "my\n",
      " \n",
      "resume\n",
      " \n",
      "as\n",
      " \n",
      "a\n",
      " \n",
      "reference.\n",
      " \n",
      "I\n",
      " \n",
      "used\n",
      " \n",
      "HuggingFace\n",
      " \n",
      "embeddings\n",
      " \n",
      "and\n",
      " \n",
      "the\n",
      " \n",
      "embedded\n",
      " \n",
      "vectors\n",
      " \n",
      "are\n",
      " \n",
      "stored\n",
      " \n",
      "in\n",
      " \n",
      "the\n",
      " \n",
      "Pinecone\n",
      " \n",
      "Vector\n",
      " \n",
      "database\n",
      " \n",
      "and\n",
      " \n",
      "prompted\n",
      " \n",
      "through\n",
      " \n",
      "OpenAI\n",
      " \n",
      "API\n",
      " \n",
      "with\n",
      " \n",
      "GPT4o\n",
      " \n",
      "mini\n",
      " \n",
      "LLM\n",
      " \n",
      "model.\n",
      " \n",
      "It’s\n",
      " hosted  at  Streamlit and github CONVERSATIONAL  WEATHER  AGENT  WITH  LANGCHAIN  TOOL  CALLING  This  portfolio  project  showcases  my  ability  to  implement  GenerativeAI’s  tool  calling  through  a  LangChain  agent.  \n",
      "I\n",
      " \n",
      "defined\n",
      " \n",
      "the\n",
      " \n",
      "functions\n",
      " \n",
      "which\n",
      " \n",
      "are\n",
      " \n",
      "bound\n",
      " \n",
      "as\n",
      " \n",
      "tools\n",
      " \n",
      "with\n",
      " \n",
      "a\n",
      " \n",
      "well-written\n",
      " \n",
      "docstring\n",
      " \n",
      "and\n",
      " \n",
      "a\n",
      " \n",
      "proper\n",
      " \n",
      "prompt,\n",
      " \n",
      "the\n",
      " \n",
      "LLM\n",
      " \n",
      "automatically\n",
      " \n",
      "decides\n",
      " \n",
      "which\n",
      " \n",
      "tool\n",
      " \n",
      "to\n",
      " \n",
      "call\n",
      " \n",
      "in\n",
      " \n",
      "what\n",
      " \n",
      "order\n",
      " \n",
      "and\n",
      " \n",
      "reports\n",
      " \n",
      "the\n",
      " \n",
      "current\n",
      " \n",
      "weather\n",
      " \n",
      "or\n",
      " \n",
      "forecast.\n",
      " \n",
      "LLM\n",
      " \n",
      "answers\n",
      "\n",
      "mobile\n",
      " \n",
      "phones\n",
      " \n",
      "of\n",
      " \n",
      "the\n",
      " \n",
      "house\n",
      " \n",
      "owners\n",
      " \n",
      "and\n",
      " \n",
      "turn\n",
      " \n",
      "ON\n",
      " \n",
      "all\n",
      " \n",
      "the\n",
      " \n",
      "electrical\n",
      " \n",
      "appliances.\n",
      " \n",
      "If\n",
      " \n",
      "some\n",
      " \n",
      "of\n",
      " \n",
      "the\n",
      " \n",
      "devices\n",
      " \n",
      "are\n",
      " \n",
      "not\n",
      " \n",
      "required,\n",
      " \n",
      "they\n",
      " \n",
      "can\n",
      " \n",
      "be\n",
      " \n",
      "turned\n",
      " \n",
      "OFF\n",
      " \n",
      "by\n",
      " \n",
      "the\n",
      " \n",
      "web\n",
      " \n",
      "application\n",
      " \n",
      "designed\n",
      " \n",
      "with\n",
      " \n",
      "PHP\n",
      " \n",
      "programmed\n",
      " \n",
      "in\n",
      " \n",
      "RPi.\n",
      " \n",
      "EXPERIENCE\n",
      " Cloutics  Coders  Inc.,  United  States  —  Data  Scientist  – Mar  2024  -  Present\n",
      " ●  Worked  on  GenAI  with  LLM  using  RAG,  for  creating  a  Chat  Assistant  for  internal  project  \n",
      "documentation.\n",
      " \n",
      " ●  Developed  API  Interface  (With  Flask  API)  for  HR  portal  for  all  the  recruiters  to  query   the  HR  policies  ,  \n",
      "employee\n",
      " \n",
      "related\n",
      " \n",
      "information\n",
      " \n",
      "and\n",
      " \n",
      "other\n",
      " \n",
      "documentation\n",
      " \n",
      "with\n",
      "  \n",
      "GenAI\n",
      " \n",
      "with\n",
      " \n",
      "LLM\n",
      " \n",
      "using\n",
      " \n",
      "RAG\n",
      ".\n",
      "Human: Give educational background of Haripriya Brief it in at most 35 words or the count limit given in the previous sentence.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'question': 'Give educational background of Haripriya Brief it in at most 35 words or the count limit given in the previous sentence.', 'chat_history': [], 'answer': 'Haripriya excelled academically, achieving School First in both SSLC and Higher Secondary School with 97% marks, and District First in the Sri Ramanujan Maths Aptitude Test and Second in a Maths Quiz during HSC.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.vectorstores import Pinecone as pc_vector\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "import os\n",
    "from pinecone import Pinecone\n",
    "from dotenv import load_dotenv\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "username = 'hari'\n",
    "\n",
    "def configure_retriever(index_name):\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L12-v1\")\n",
    "\n",
    "    docsearch = pc_vector.from_existing_index(index_name, embeddings)\n",
    "    retriever = docsearch.as_retriever(search_type=\"mmr\")\n",
    "    return retriever\n",
    "\n",
    "db_path = 'local_sqlite_db.db'\n",
    "msgs = SQLChatMessageHistory(\n",
    "    session_id=username,\n",
    "    connection=\"sqlite:///\" + db_path  # This is the SQLite connection string\n",
    ")\n",
    "\n",
    "# index_name = \"my-portfolio\"\n",
    "index_name = 'test-my-portfolio'\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", chat_memory=msgs, return_messages=True)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "        model_name=\"gpt-4o-mini\", openai_api_key=openai_api_key, temperature=0, streaming=True\n",
    "    )\n",
    "\n",
    "system_prompt = \"You are A CHAT ASSISTANT even with or without context and you are NOT Haripriya. You are supposed to answer the questions asked only about Haripriya and you are NOT Haripriya. Use the following pieces of retrieved context to answer the question.\\n\\n{context}\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "[\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{question}\"),\n",
    "]\n",
    ")\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm, retriever=configure_retriever(index_name), memory=memory, verbose=True,\n",
    "        combine_docs_chain_kwargs={\"prompt\": qa_prompt},\n",
    ")\n",
    "\n",
    "user_query = 'Give educational background of Haripriya'\n",
    "user_query += ' Brief it in at most 35 words or the count limit given in the previous sentence.'\n",
    "response = qa_chain.invoke({\"question\":user_query})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-LLM Evaluations\n",
    "<a id='non_llm_evaluations'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BLEU Score: Compares the generated text to reference texts, assessing the overlap of n-grams (sequences of words).\n",
    "- ROUGE Score: Similar to BLEU, but focuses on recall, measuring how much of the reference content is captured in the generated text.\n",
    "- METEOR: Considers synonyms and paraphrases, aiming to better align with human judgment.\n",
    "- BERTScore: Evaluates text by comparing the similarity of contextual embeddings, focusing on meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk  # For BLEU and other metrics (if needed)\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score\n",
    "import numpy as np\n",
    "\n",
    "# 1. BLEU Score\n",
    "def calculate_bleu(generated, references):\n",
    "    \"\"\"Calculates BLEU score.\"\"\"\n",
    "    smoothing = SmoothingFunction().method4  # Choose a smoothing function\n",
    "    bleu_scores = []\n",
    "    for i in range(len(generated)):\n",
    "        score = sentence_bleu(references[i], generated[i].split(), smoothing_function=smoothing)\n",
    "        bleu_scores.append(score)\n",
    "    return np.mean(bleu_scores)\n",
    "\n",
    "# 2. ROUGE Score\n",
    "def calculate_rouge(generated, references):\n",
    "    \"\"\"Calculates ROUGE scores (ROUGE-1, ROUGE-2, ROUGE-L).\"\"\"\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    rouge_1_scores = []\n",
    "    rouge_2_scores = []\n",
    "    rouge_l_scores = []\n",
    "\n",
    "    for i in range(len(generated)):\n",
    "        scores = scorer.score(references[i][0], generated[i]) # reference is a list of sentences, we take the first one\n",
    "        rouge_1_scores.append(scores['rouge1'].fmeasure)\n",
    "        rouge_2_scores.append(scores['rouge2'].fmeasure)\n",
    "        rouge_l_scores.append(scores['rougeL'].fmeasure)\n",
    "    return np.mean(rouge_1_scores), np.mean(rouge_2_scores), np.mean(rouge_l_scores)\n",
    "\n",
    "# 3. BERTScore\n",
    "def calculate_bertscore(generated, references):\n",
    "    \"\"\"Calculates BERTScore.\"\"\"\n",
    "    P, R, F1 = score(generated, [ref[0] for ref in references], lang=\"en\")  # reference is a list of sentences, we take the first one\n",
    "    return np.mean(P.cpu().numpy()), np.mean(R.cpu().numpy()), np.mean(F1.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clearing out session when required\n",
    "msgs.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore Precision: 0.8457125425338745\n",
      "BERTScore Recall: 0.861638069152832\n",
      "BERTScore F1: 0.8536010384559631\n"
     ]
    }
   ],
   "source": [
    "reference_texts = [['Haripriya had good scores in academics during school and studied Electronics and Communication Engineering. She also is studying micromasters in Statistics and Data science']]\n",
    "generated_texts = ['Haripriya excelled academically, achieving School First in both SSLC and Higher Secondary School with 97% marks, and District First in the Sri Ramanujan Maths Aptitude Test and Second in a Maths Quiz during HSC.']\n",
    "\n",
    "bert_p, bert_r, bert_f1 = calculate_bertscore(generated_texts, reference_texts)\n",
    "print(f\"BERTScore Precision: {bert_p}\")\n",
    "print(f\"BERTScore Recall: {bert_r}\")\n",
    "print(f\"BERTScore F1: {bert_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is low. I'm expecting a score of 90 and above. I'll be re-creating the index by modifying the pdf and chunk size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modification 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified chunk size and the pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Assistant: I can answer any question about Haripriya Rajendran. How can I help you?\n",
      "Human: Give educational background of Haripriya Brief it in at most 35 words or the count limit given in the previous sentence.\n",
      "Assistant: Haripriya Rajendran has completed a Micromasters in ML with Python, Google Advanced and Data Analytics Professional Certificates, and a Machine Learning certificate from Stanford University, among other relevant courses and certifications.\n",
      "Follow Up Input: Give educational background of Haripriya Brief it in at most 35 words or the count limit given in the previous sentence.\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are A CHAT ASSISTANT even with or without context and you are NOT Haripriya. You are supposed to answer the questions asked only about Haripriya and you are NOT Haripriya. Use the following pieces of retrieved context to answer the question.\n",
      "\n",
      "LINKS\n",
      " ●  Portfolio  streamlit  :  bit.ly/HpPortfolio GitHub:  https://github.com/hari04hp ●  Portfolio  tool  calling  project  published:   https://haripriya-rajendran-weather-agent.streamlit.app/  GitHub  :   https://github.com/hari04hp/langchain-weather-tool-calling ●  Fine  Tuning  Gemma  with  LoRA:  https://github.com/hari04hp/fine-tuning-with-LLMs  ●  LinkedIn  special  appreciation  post  :  https://www.linkedin.com/posts/applied-data-finance_adfs-impact-on-women-in-data-science-haripriya-activity-7062689220418506752-SrnY/?utm_source=share&utm_medium=member_desktop ●  Micromasters  ML  with  python  Certificate:  https://courses.edx.org/certificates/0bb4d2a3afaf4084b9769e38fe2e3621 ●  Google  Advanced  Data  Analytics  Professional  Certificate  :  https://coursera.org/share/834777bcafebf5b786b8ccf9bfec2310 ●  Google  Data  Analytics  Professional  Certificate  :  https://coursera.org/share/a6cbcd753c518c0fa1e1963280ab8837 ●  Udemy  ML  certificate:  https://www.udemy.com/certificate/UC-AFTSGUV3/ ●  GenAI  Fundamentals  from  Google  Cloud  skills  boost  :  https://www.cloudskillsboost.google/public_profiles/cbdc244d-9d0c-47d9-97cf-9df0f2ce0b34/badges/8137055 ●  “Machine  Learning”  -  Stanford  University  -  Coursera  Certificate  :  https://coursera.org/share/3abf0fbf2896aab2351dd1b0f6a15e2f ●  Programming  for  Everybody  (Python)-  U-M  -  Coursera  Certificate  :  https://coursera.org/share/82e42e01b306f5a268181bb5267246c1 ●  MITx  Micromasters:  https://micromasters.mit.edu/ds/ ●  Kaggle  Page  :  https://www.kaggle.com/haripriya04raj ●  MachineHack  :  https://machinehack.com/user/5ef0a238b7efcc325e3907d1 ●  Case  Study  in  RPubs:  https://rpubs.com/haripriya_rhp/cyclistic-case-study ●  Case  Study  in  GitHub  :  https://github.com/hari04hp/google-advanced-capstone\n",
      "\n",
      "the\n",
      " \n",
      "Prediction\n",
      " \n",
      "and\n",
      " \n",
      "Confidence\n",
      " \n",
      "Intervals\n",
      ".\n",
      " ●  Can  make  data-driven  decisions  by  exploring,  transforming  and  analyzing  large  loan  data  sets,  by  monitoring  \n",
      "credit\n",
      " \n",
      "risk\n",
      " \n",
      "and\n",
      " \n",
      "default\n",
      " \n",
      "rates\n",
      " \n",
      "(PD,\n",
      " \n",
      "marginal\n",
      " \n",
      "bad\n",
      " \n",
      "rates\n",
      " \n",
      "and\n",
      " \n",
      "SMM)\n",
      " \n",
      "categorized\n",
      " \n",
      "by\n",
      " \n",
      "APRs\n",
      " \n",
      "and\n",
      " \n",
      "Pools\n",
      " \n",
      "using\n",
      " \n",
      "tableau.\n",
      " \n",
      "Created\n",
      " \n",
      "and\n",
      " \n",
      "Deployed\n",
      " \n",
      "datasources\n",
      " \n",
      "using\n",
      " \n",
      "RedShift\n",
      " \n",
      "tables\n",
      " \n",
      "to\n",
      " \n",
      "tableau\n",
      " \n",
      "using\n",
      " \n",
      "Tableau\n",
      " \n",
      "desktop\n",
      " \n",
      "version.\n",
      " \n",
      " ●  Performed  Retro  Data  preparation  and  Analysis  on  new  data  products.  Framed  proper  API  request  for  a\n",
      "\n",
      "the\n",
      " \n",
      "web\n",
      " \n",
      "application\n",
      " \n",
      "designed\n",
      " \n",
      "with\n",
      " \n",
      "PHP\n",
      " \n",
      "programmed\n",
      " \n",
      "in\n",
      " \n",
      "RPi.\n",
      " \n",
      "EXPERIENCE\n",
      " Cloutics  Coders  Inc.,  United  States  —  Data  Scientist  – Mar  2024  -  Present\n",
      " ●  Worked  on  GenAI  with  LLM  using  RAG,  for  creating  a  Chat  Assistant  for  internal  project  \n",
      "documentation.\n",
      " \n",
      " ●  Developed  API  Interface  (With  Flask  API)  for  HR  portal  for  all  the  recruiters  to  query   the  HR  policies  ,  \n",
      "employee\n",
      " \n",
      "related\n",
      " \n",
      "information\n",
      " \n",
      "and\n",
      " \n",
      "other\n",
      " \n",
      "documentation\n",
      " \n",
      "with\n",
      "  \n",
      "GenAI\n",
      " \n",
      "with\n",
      " \n",
      "LLM\n",
      " \n",
      "using\n",
      " \n",
      "RAG\n",
      ".\n",
      "\n",
      "new  data  provider  for  classifying  the  customer’s  industry  type,  after  analysing  the  data  during  COVID-19  \n",
      "Pandemic\n",
      " \n",
      "in\n",
      " \n",
      "order\n",
      " \n",
      "to\n",
      " \n",
      "decide\n",
      " \n",
      "based\n",
      " \n",
      "on\n",
      " \n",
      "the\n",
      " \n",
      "recession\n",
      " \n",
      "in\n",
      " \n",
      "particular\n",
      " \n",
      "industry\n",
      " \n",
      "type.\n",
      " ●  Actively  participated  in  all  hackathons  and  innovation  days  conducted  by  ADF  (BERT  algorithm  for  NLP  \n",
      "using\n",
      " \n",
      "Kaggle\n",
      " \n",
      "platform,\n",
      " \n",
      "a\n",
      " \n",
      "new\n",
      " \n",
      "version\n",
      " \n",
      "of\n",
      " \n",
      "Dependent\n",
      " \n",
      "variable\n",
      " \n",
      "for\n",
      " \n",
      "the\n",
      " \n",
      "risk\n",
      " \n",
      "models).\n",
      " ●  Worked  on  migrating  the  models  to  updated  python  version  and  optimising  the  existing  models.  \n",
      "MQ  Spectrum  Pte  Ltd,  Chennai  — \n",
      "Assistant  Technical  Lead  and  SDE  II   –  Oct  2017  -  Aug  2019\n",
      " Worked  in  Liferay  Platform,  Apache  Tomcat  Web  application  with  Java,  J2EE,  ASP.NET,  WPF   and  Search  Indexer  \n",
      "in\n",
      " \n",
      "C#,\n",
      " \n",
      "Moodle\n",
      " \n",
      "framework\n",
      " \n",
      "and\n",
      " \n",
      "SQL\n",
      " \n",
      "Server.\n",
      " \n",
      "AWARDS\n",
      " ●  A  special  appreciation  post  on  company’s  LinkedIn page.  ●  SECOND prize  in  ADF’s  Data  science  hackathon  and  a  Special  award  in  Technology  Hackathon.  ●  ADF  Excellence  Award from  ADF  for  my  dedicated  work.  ●  DISTRICT  FIRST  in  Sri  Ramanujan  Maths  aptitude  test  and  SECOND  in  Maths  Quiz  during  my  HSC.  ●  School  First  in  academics  in  both  SSLC  and  Higher  secondary  school  receiving  97%  of  marks. \n",
      "LINKS\n",
      "Human: What is the educational background of Haripriya Rajendran, summarized in no more than 35 words?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'question': 'Give educational background of Haripriya Brief it in at most 35 words or the count limit given in the previous sentence.', 'chat_history': [AIMessage(content='I can answer any question about Haripriya Rajendran. How can I help you?', additional_kwargs={}, response_metadata={}), HumanMessage(content='Give educational background of Haripriya Brief it in at most 35 words or the count limit given in the previous sentence.', additional_kwargs={}, response_metadata={}), AIMessage(content='Haripriya Rajendran has completed a Micromasters in ML with Python, Google Advanced and Data Analytics Professional Certificates, and a Machine Learning certificate from Stanford University, among other relevant courses and certifications.', additional_kwargs={}, response_metadata={})], 'answer': 'Haripriya Rajendran has completed a Micromasters in ML with Python, Google Advanced Data Analytics and Data Analytics Professional Certificates, and a Machine Learning course from Stanford University, among other certifications.'}\n"
     ]
    }
   ],
   "source": [
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm, retriever=configure_retriever(index_name), memory=memory, verbose=True,\n",
    "        combine_docs_chain_kwargs={\"prompt\": qa_prompt},\n",
    ")\n",
    "\n",
    "user_query = 'Give educational background of Haripriya'\n",
    "user_query += ' Brief it in at most 35 words or the count limit given in the previous sentence.'\n",
    "response = qa_chain.invoke({\"question\":user_query})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore Precision: 0.8500571846961975\n",
      "BERTScore Recall: 0.8697115182876587\n",
      "BERTScore F1: 0.8597720265388489\n"
     ]
    }
   ],
   "source": [
    "reference_texts = [['Haripriya had good scores in academics during school and studied Electronics and Communication Engineering. She also is studying micromasters in Statistics and Data science']]\n",
    "\n",
    "generated_texts = ['Haripriya Rajendran has completed a Micromasters in ML with Python, Google Advanced Data Analytics and Data Analytics Professional Certificates, and a Machine Learning course from Stanford University, among other certifications.']\n",
    "\n",
    "bert_p, bert_r, bert_f1 = calculate_bertscore(generated_texts, reference_texts)\n",
    "print(f\"BERTScore Precision: {bert_p}\")\n",
    "print(f\"BERTScore Recall: {bert_r}\")\n",
    "print(f\"BERTScore F1: {bert_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not what I was expecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modification 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified the whole embedding model back to the older L6 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are A CHAT ASSISTANT even with or without context and you are NOT Haripriya. You are supposed to answer the questions asked only about Haripriya and you are NOT Haripriya. Use the following pieces of retrieved context to answer the question.\n",
      "\n",
      "the\n",
      " \n",
      "web\n",
      " \n",
      "application\n",
      " \n",
      "designed\n",
      " \n",
      "with\n",
      " \n",
      "PHP\n",
      " \n",
      "programmed\n",
      " \n",
      "in\n",
      " \n",
      "RPi.\n",
      " \n",
      "EXPERIENCE\n",
      " Cloutics  Coders  Inc.,  United  States  —  Data  Scientist  – Mar  2024  -  Present\n",
      " ●  Worked  on  GenAI  with  LLM  using  RAG,  for  creating  a  Chat  Assistant  for  internal  project  \n",
      "documentation.\n",
      " \n",
      " ●  Developed  API  Interface  (With  Flask  API)  for  HR  portal  for  all  the  recruiters  to  query   the  HR  policies  ,  \n",
      "employee\n",
      " \n",
      "related\n",
      " \n",
      "information\n",
      " \n",
      "and\n",
      " \n",
      "other\n",
      " \n",
      "documentation\n",
      " \n",
      "with\n",
      "  \n",
      "GenAI\n",
      " \n",
      "with\n",
      " \n",
      "LLM\n",
      " \n",
      "using\n",
      " \n",
      "RAG\n",
      ".\n",
      "\n",
      "which\n",
      " \n",
      "reduced\n",
      " \n",
      "the\n",
      " \n",
      "fraud\n",
      " \n",
      "upto\n",
      " \n",
      "10%\n",
      ".\n",
      " \n",
      " ●  Model  built  to  predicting  External  risk’s  sensitivity  using  stratified  sampling  and  propensity  sample  \n",
      "weighting\n",
      " \n",
      "for\n",
      " \n",
      "large\n",
      " \n",
      "dataset\n",
      " \n",
      "over\n",
      " \n",
      "100K\n",
      " \n",
      "records.\n",
      " \n",
      "These\n",
      " \n",
      "models\n",
      " \n",
      "were\n",
      " \n",
      "built\n",
      " \n",
      "to\n",
      " \n",
      "be\n",
      " \n",
      "orthogonal\n",
      " \n",
      "to\n",
      " \n",
      "the\n",
      " \n",
      "existing\n",
      " \n",
      "ones.\n",
      " ●  Created  an  automated  model  performance  evaluation  framework  that  evaluates  the  newly  added  models  \n",
      "and\n",
      " \n",
      "also\n",
      " \n",
      "suggests\n",
      " \n",
      "how\n",
      " \n",
      "they\n",
      " \n",
      "perform\n",
      " \n",
      "well\n",
      " \n",
      "in\n",
      " \n",
      "addition\n",
      " \n",
      "to\n",
      " \n",
      "the\n",
      " \n",
      "existing\n",
      " \n",
      "ones.\n",
      " \n",
      "It\n",
      " \n",
      "also\n",
      " \n",
      "suggests\n",
      " \n",
      "the\n",
      " \n",
      "retirement\n",
      " \n",
      "of\n",
      " \n",
      "existing\n",
      " \n",
      "models\n",
      " \n",
      "when\n",
      " \n",
      "model\n",
      " \n",
      "drift\n",
      " \n",
      "happens.\n",
      " \n",
      "This\n",
      " \n",
      "framework\n",
      " \n",
      "reduced\n",
      " \n",
      "around\n",
      " \n",
      "30%\n",
      " \n",
      "of\n",
      " \n",
      "the\n",
      " \n",
      "manual\n",
      " \n",
      "workload\n",
      " \n",
      "of\n",
      " \n",
      "the\n",
      " \n",
      "data\n",
      " \n",
      "scientists.\n",
      " ●  Performed  A/B ,  hypothesis  tests  and  causal  inference  analysis  to  see  if  the  reduction  in  risk  is  significant  if  a  \n",
      "new\n",
      " \n",
      "rule\n",
      " \n",
      "is\n",
      " \n",
      "added\n",
      " \n",
      "in\n",
      " \n",
      "Underwriting.\n",
      " \n",
      "Proved\n",
      " \n",
      "that\n",
      " \n",
      "adding\n",
      " \n",
      "this\n",
      " \n",
      "new\n",
      " \n",
      "rule\n",
      " \n",
      "in\n",
      " \n",
      "Underwriting\n",
      " \n",
      "would\n",
      " \n",
      "cause\n",
      " \n",
      "a\n",
      " \n",
      "significant\n",
      " \n",
      "reduction\n",
      " \n",
      "in\n",
      " \n",
      "risk\n",
      " \n",
      "around\n",
      " \n",
      "2%\n",
      " \n",
      "which\n",
      " \n",
      "was\n",
      " \n",
      "eventually\n",
      " \n",
      "put\n",
      " \n",
      "into\n",
      " \n",
      "production\n",
      ".\n",
      " \n",
      "Also\n",
      " \n",
      "wrote\n",
      " \n",
      "functions\n",
      " \n",
      "for\n",
      " \n",
      "Monte\n",
      " \n",
      "carlo\n",
      " \n",
      "simulation\n",
      " \n",
      "in\n",
      " \n",
      "a\n",
      " \n",
      "project\n",
      " \n",
      "where\n",
      " \n",
      "we\n",
      " \n",
      "simulated\n",
      " \n",
      "past\n",
      " \n",
      "customers\n",
      " \n",
      "to\n",
      " \n",
      "be\n",
      " \n",
      "in\n",
      " \n",
      "a\n",
      " \n",
      "present\n",
      " \n",
      "scenario.\n",
      " ●  Worked  cross-functionally   with  the  Machine  Learning  Engineering  team,  to  give  insights  on  ML  algorithms  \n",
      "and\n",
      " \n",
      "in\n",
      " \n",
      "developing\n",
      " \n",
      "modules\n",
      " \n",
      "and\n",
      " \n",
      "pipelines.\n",
      " \n",
      "Created\n",
      " \n",
      "a\n",
      " \n",
      "Jenkins\n",
      " \n",
      "automation\n",
      " \n",
      "pipeline\n",
      " \n",
      "for\n",
      " \n",
      "report\n",
      " \n",
      "generation\n",
      " \n",
      "using\n",
      " \n",
      "Python\n",
      " \n",
      "and\n",
      " \n",
      "groovy.\n",
      " \n",
      " ●  Predicted  the  expected  NPV  with  the  current  risk  by  building  a  model  using  the  forecasted  result  and  \n",
      "visualized\n",
      " \n",
      "using\n",
      " \n",
      "the\n",
      " \n",
      "Prediction\n",
      " \n",
      "and\n",
      " \n",
      "Confidence\n",
      " \n",
      "Intervals\n",
      ".\n",
      " ●  Can  make  data-driven  decisions  by  exploring,  transforming  and  analyzing  large  loan  data  sets,  by  monitoring  \n",
      "credit\n",
      " \n",
      "risk\n",
      " \n",
      "and\n",
      " \n",
      "default\n",
      " \n",
      "rates\n",
      " \n",
      "(PD,\n",
      " \n",
      "marginal\n",
      " \n",
      "bad\n",
      " \n",
      "rates\n",
      " \n",
      "and\n",
      " \n",
      "SMM)\n",
      " \n",
      "categorized\n",
      " \n",
      "by\n",
      " \n",
      "APRs\n",
      " \n",
      "and\n",
      "\n",
      "new  data  provider  for  classifying  the  customer’s  industry  type,  after  analysing  the  data  during  COVID-19  \n",
      "Pandemic\n",
      " \n",
      "in\n",
      " \n",
      "order\n",
      " \n",
      "to\n",
      " \n",
      "decide\n",
      " \n",
      "based\n",
      " \n",
      "on\n",
      " \n",
      "the\n",
      " \n",
      "recession\n",
      " \n",
      "in\n",
      " \n",
      "particular\n",
      " \n",
      "industry\n",
      " \n",
      "type.\n",
      " ●  Actively  participated  in  all  hackathons  and  innovation  days  conducted  by  ADF  (BERT  algorithm  for  NLP  \n",
      "using\n",
      " \n",
      "Kaggle\n",
      " \n",
      "platform,\n",
      " \n",
      "a\n",
      " \n",
      "new\n",
      " \n",
      "version\n",
      " \n",
      "of\n",
      " \n",
      "Dependent\n",
      " \n",
      "variable\n",
      " \n",
      "for\n",
      " \n",
      "the\n",
      " \n",
      "risk\n",
      " \n",
      "models).\n",
      " ●  Worked  on  migrating  the  models  to  updated  python  version  and  optimising  the  existing  models.  \n",
      "MQ  Spectrum  Pte  Ltd,  Chennai  — \n",
      "Assistant  Technical  Lead  and  SDE  II   –  Oct  2017  -  Aug  2019\n",
      " Worked  in  Liferay  Platform,  Apache  Tomcat  Web  application  with  Java,  J2EE,  ASP.NET,  WPF   and  Search  Indexer  \n",
      "in\n",
      " \n",
      "C#,\n",
      " \n",
      "Moodle\n",
      " \n",
      "framework\n",
      " \n",
      "and\n",
      " \n",
      "SQL\n",
      " \n",
      "Server.\n",
      " \n",
      "AWARDS\n",
      " ●  A  special  appreciation  post  on  company’s  LinkedIn page.  ●  SECOND prize  in  ADF’s  Data  science  hackathon  and  a  Special  award  in  Technology  Hackathon.  ●  ADF  Excellence  Award from  ADF  for  my  dedicated  work.  ●  DISTRICT  FIRST  in  Sri  Ramanujan  Maths  aptitude  test  and  SECOND  in  Maths  Quiz  during  my  HSC.  ●  School  First  in  academics  in  both  SSLC  and  Higher  secondary  school  receiving  97%  of  marks. \n",
      "LINKS\n",
      "\n",
      "the\n",
      " \n",
      "Prediction\n",
      " \n",
      "and\n",
      " \n",
      "Confidence\n",
      " \n",
      "Intervals\n",
      ".\n",
      " ●  Can  make  data-driven  decisions  by  exploring,  transforming  and  analyzing  large  loan  data  sets,  by  monitoring  \n",
      "credit\n",
      " \n",
      "risk\n",
      " \n",
      "and\n",
      " \n",
      "default\n",
      " \n",
      "rates\n",
      " \n",
      "(PD,\n",
      " \n",
      "marginal\n",
      " \n",
      "bad\n",
      " \n",
      "rates\n",
      " \n",
      "and\n",
      " \n",
      "SMM)\n",
      " \n",
      "categorized\n",
      " \n",
      "by\n",
      " \n",
      "APRs\n",
      " \n",
      "and\n",
      " \n",
      "Pools\n",
      " \n",
      "using\n",
      " \n",
      "tableau.\n",
      " \n",
      "Created\n",
      " \n",
      "and\n",
      " \n",
      "Deployed\n",
      " \n",
      "datasources\n",
      " \n",
      "using\n",
      " \n",
      "RedShift\n",
      " \n",
      "tables\n",
      " \n",
      "to\n",
      " \n",
      "tableau\n",
      " \n",
      "using\n",
      " \n",
      "Tableau\n",
      " \n",
      "desktop\n",
      " \n",
      "version.\n",
      " \n",
      " ●  Performed  Retro  Data  preparation  and  Analysis  on  new  data  products.  Framed  proper  API  request  for  a\n",
      "Human: Give educational background of Haripriya Brief it in at most 35 words or the count limit given in the previous sentence.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'question': 'Give educational background of Haripriya Brief it in at most 35 words or the count limit given in the previous sentence.', 'chat_history': [], 'answer': 'Haripriya excelled academically, achieving school first in both SSLC and Higher Secondary with 97% marks, and district first in the Sri Ramanujan Maths aptitude test, along with second place in a Maths quiz.'}\n"
     ]
    }
   ],
   "source": [
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm, retriever=configure_retriever(index_name), memory=memory, verbose=True,\n",
    "        combine_docs_chain_kwargs={\"prompt\": qa_prompt},\n",
    ")\n",
    "\n",
    "user_query = 'Give educational background of Haripriya'\n",
    "user_query += ' Brief it in at most 35 words or the count limit given in the previous sentence.'\n",
    "response = qa_chain.invoke({\"question\":user_query})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore Precision: 0.857337474822998\n",
      "BERTScore Recall: 0.861737847328186\n",
      "BERTScore F1: 0.8595320582389832\n"
     ]
    }
   ],
   "source": [
    "reference_texts = [['Haripriya had good scores in academics during school and studied Electronics and Communication Engineering. She also is studying micromasters in Statistics and Data science']]\n",
    "\n",
    "generated_texts = ['Haripriya excelled academically, achieving school first in both SSLC and Higher Secondary with 97% marks, and district first in the Sri Ramanujan Maths aptitude test, along with second place in a Maths quiz.']\n",
    "\n",
    "bert_p, bert_r, bert_f1 = calculate_bertscore(generated_texts, reference_texts)\n",
    "print(f\"BERTScore Precision: {bert_p}\")\n",
    "print(f\"BERTScore Recall: {bert_r}\")\n",
    "print(f\"BERTScore F1: {bert_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is still low. Let's use some actual LLM-RAG's evaluation  metrics and see what might be the issues with context, input or output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics using Deepval - LLM Evaluation\n",
    "<a id='llm_evaluations'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have taken the input, output and the contexts from the above query that was ran with langchain. It's in the output cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import contexts_for_testing\n",
    "contexts = contexts_for_testing.context_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1136, 816, 493, 1742]\n"
     ]
    }
   ],
   "source": [
    "print([len(context) for context in contexts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac0d0f477e9428880fda3630d91164d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4344f139628a4a1e9c0d659975fff345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contextualRecall :  0.0\n",
      "The score is 0.00 because none of the sentences in the expected output align with any of the nodes in the retrieval context, as there are no relevant quotes to support Haripriya's academic achievements or her current studies.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aec1be8446e406399b375d9040e4930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contextualRelevancy :  0.3448275862068966\n",
      "The score is 0.34 because while there are relevant educational achievements mentioned, such as 'DISTRICT FIRST in Sri Ramanujan Maths aptitude test' and various certificates from prestigious institutions like 'MITx' and 'Stanford University', the majority of the retrieval context is focused on technical skills and work experiences that do not pertain to Haripriya's educational background.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contextualPrecision :  0.3333333333333333\n",
      "The score is 0.33 because while there is one relevant node that provides direct information about Haripriya's educational background, the higher-ranked nodes predominantly contain irrelevant content. Specifically, the first node ranks highest but states, \"The first document does not mention Haripriya's academic background or any relevant details about her education,\" thus contributing to the lower score. Furthermore, the second and fourth nodes also do not provide pertinent information related to the request, confirming that relevant nodes are not ranked high enough.\n"
     ]
    }
   ],
   "source": [
    "from deepeval.metrics import ContextualRecallMetric, ContextualRelevancyMetric, ContextualPrecisionMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "# Actual output from your LLM application\n",
    "actual_output = \"Haripriya Rajendran excelled academically, achieving school first in both SSLC and Higher Secondary with 97% marks, and district first in the Sri Ramanujan Maths aptitude test, alongside various professional certifications in data science and analytics.\"\n",
    "\n",
    "# Replace this with the expected output from your RAG generator\n",
    "expected_output = \"'Haripriya had good scores in academics during school and studied Electronics and Communication Engineering. She also is studying micromasters in Statistics and Data science'\"\n",
    "\n",
    "# Replace this with the actual retrieved context from your RAG pipeline\n",
    "retrieval_context = contexts\n",
    "\n",
    "contextualRecall = ContextualRecallMetric(\n",
    "    threshold=0.7,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    include_reason=True\n",
    ")\n",
    "test_case = LLMTestCase(\n",
    "    input=\"Give educational background of Haripriya\",\n",
    "    actual_output=actual_output,\n",
    "    expected_output=expected_output,\n",
    "    retrieval_context=retrieval_context\n",
    ")\n",
    "\n",
    "contextualRelevancy = ContextualRelevancyMetric(\n",
    "    threshold=0.7,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    include_reason=True\n",
    ")\n",
    "\n",
    "contextualPrecision = ContextualPrecisionMetric(\n",
    "    threshold=0.7,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    include_reason=True\n",
    ")\n",
    "\n",
    "contextualRecall.measure(test_case)\n",
    "print(\"contextualRecall : \", contextualRecall.score)\n",
    "print(contextualRecall.reason)\n",
    "\n",
    "contextualRelevancy.measure(test_case)\n",
    "print(\"contextualRelevancy : \", contextualRelevancy.score)\n",
    "print(contextualRelevancy.reason)\n",
    "\n",
    "contextualPrecision.measure(test_case)\n",
    "print(\"contextualPrecision : \", contextualPrecision.score)\n",
    "print(contextualPrecision.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47e7032f40c4f749335de0fe34b84de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness : 0.75\n",
      "The score is 0.75 because while the actual output accurately conveys Haripriya Rajendran's top achievements in her classes, it incorrectly interprets 'first in academics' as 'school first'. This slight misalignment leads to a reduction in faithfulness to the retrieval context.\n"
     ]
    }
   ],
   "source": [
    "from deepeval.metrics import FaithfulnessMetric\n",
    "faithfulness = FaithfulnessMetric(\n",
    "    threshold=0.7,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    include_reason=True\n",
    ")\n",
    "\n",
    "faithfulness.measure(test_case)\n",
    "print(\"faithfulness :\", faithfulness.score)\n",
    "print(faithfulness.reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The contextual recall is just 0 telling that none of the contexts actually aligns with the expected output\n",
    "- The contextual relevancy is also very low and explains why there is a very low score in a more human understandable way. This checks the relevancy between the input and the context \n",
    "- The contexual precision is also low because only one of the four documents is somewhat similar to the input and is also not ranked at the top. There is an irrelevant document at the top\n",
    "- faithfulness has a good score because the actual output is faithful to the context. The LLM actually answers properly with whatever context it has.\n",
    "\n",
    "So, from this we can understand that the retrieved context is actually the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modification 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I figured that the context given is not as expected and the context format is also not proper since it's extracted from a formatted pdf. So, I tried to populate the pinecone index with Docxloaders instead of pypdfloader and used a word document. Now this document is used to create vectors and then used them as context. Hopefully, there won't be any formatting issue this time and the context is proper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test sample 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are A CHAT ASSISTANT even with or without context and you are NOT Haripriya. You are supposed to answer the questions asked only about Haripriya and you are NOT Haripriya. Use the following pieces of retrieved context to answer the question.\n",
      "\n",
      "Performed Retro Data preparation and Analysis on new data products. Framed proper API request for a new data provider for classifying the customer’s industry type, after analysing the data during COVID-19 Pandemic in order to decide based on the recession in particular industry type.\n",
      "\n",
      "Actively participated in all hackathons and innovation days conducted by ADF (BERT algorithm for NLP using Kaggle platform, a new version of Dependent variable for the risk models).\n",
      "\n",
      "Worked on migrating the models to updated python version and optimising the existing models.\n",
      "\n",
      "MQ Spectrum Pte Ltd, Chennai — Assistant Technical Lead and SDE II  – Oct 2017 - Aug 2019\n",
      "\n",
      "Worked in Liferay Platform, Apache Tomcat Web application with Java, J2EE, ASP.NET, WPF  and Search Indexer in C#, Moodle framework and SQL Server.\n",
      "\n",
      "AWARDS\n",
      "\n",
      "A special appreciation post on company’s LinkedIn page.\n",
      "\n",
      "SECOND prize in ADF’s Data science hackathon and a Special award in Technology Hackathon.\n",
      "\n",
      "ADF Excellence Award from ADF for my dedicated work.\n",
      "\n",
      "DISTRICT FIRST in Sri Ramanujan Maths aptitude test and SECOND in Maths Quiz during my HSC.\n",
      "\n",
      "School First in academics in both SSLC and Higher secondary school receiving 97% of marks.\n",
      "\n",
      "LINKS\n",
      "\n",
      "Portfolio streamlit : bit.ly/HpPortfolio GitHub: https://github.com/hari04hp\n",
      "\n",
      "Portfolio tool calling project published:  https://haripriya-rajendran-weather-agent.streamlit.app/  GitHub :  https://github.com/hari04hp/langchain-weather-tool-calling\n",
      "\n",
      "Fine Tuning Gemma with LoRA: https://github.com/hari04hp/fine-tuning-with-LLMs \n",
      "\n",
      "LinkedIn special appreciation post : https://www.linkedin.com/posts/applied-data-finance_adfs-impact-on-women-in-data-science-haripriya-activity-7062689220418506752-SrnY/?utm_source=share&utm_medium=member_desktop\n",
      "\n",
      "Micromasters ML with python Certificate: https://courses.edx.org/certificates/0bb4d2a3afaf4084b9769e38fe2e3621\n",
      "\n",
      "Google Advanced Data Analytics Professional Certificate : https://coursera.org/share/834777bcafebf5b786b8ccf9bfec2310\n",
      "\n",
      "Micromasters ML with python Certificate: https://courses.edx.org/certificates/0bb4d2a3afaf4084b9769e38fe2e3621\n",
      "\n",
      "Google Advanced Data Analytics Professional Certificate : https://coursera.org/share/834777bcafebf5b786b8ccf9bfec2310\n",
      "\n",
      "Google Data Analytics Professional Certificate : https://coursera.org/share/a6cbcd753c518c0fa1e1963280ab8837\n",
      "\n",
      "Udemy ML certificate: https://www.udemy.com/certificate/UC-AFTSGUV3/\n",
      "\n",
      "GenAI Fundamentals from Google Cloud skills boost : https://www.cloudskillsboost.google/public_profiles/cbdc244d-9d0c-47d9-97cf-9df0f2ce0b34/badges/8137055\n",
      "\n",
      "“Machine Learning” - Stanford University - Coursera Certificate : https://coursera.org/share/3abf0fbf2896aab2351dd1b0f6a15e2f\n",
      "\n",
      "Programming for Everybody (Python)- U-M - Coursera Certificate : https://coursera.org/share/82e42e01b306f5a268181bb5267246c1\n",
      "\n",
      "MITx Micromasters: https://micromasters.mit.edu/ds/\n",
      "\n",
      "Kaggle Page : https://www.kaggle.com/haripriya04raj\n",
      "\n",
      "MachineHack : https://machinehack.com/user/5ef0a238b7efcc325e3907d1\n",
      "\n",
      "Case Study in RPubs: https://rpubs.com/haripriya_rhp/cyclistic-case-study\n",
      "\n",
      "Case Study in GitHub : https://github.com/hari04hp/google-advanced-capstone\n",
      "\n",
      "SKILLS\n",
      "\n",
      "Languages: Python (Preferred and expert), R(basics),  MySQL(expert), RedShift, MongoDB, BigQuery, [C#, Java, J2EE, PHP, Javascript](in the past role)\n",
      "\n",
      "ML and DS algorithms and libraries: Pandas, Numpy, sklearn, gunicorn/Flask(REST APIs), joblib, seaborn, matplotlib, Regression, Random Forest, XGBoost, CatBoost, LightGBM,Ray, MLFlow, Optuna, TensorFlow, Keras PyTorch, PySpark, Data Mining, Data Extraction, Data Analytics, Feature Engineering, Machine learning Engineering, Model explainability, Predictive Modelling, Exploratory Data Analysis, Statistical Analysis, Hypothesis testing, A/B testing, Deep Learning, K-Means, Recommendation systems, Reinforcement Learning, Clustering, Expectation Maximization Algorithm, NLP, GenerativeAI, LangChain, OpenAI, RAG, LLMs, Prompt Engineering, Function Calling/Tool Calling.\n",
      "\n",
      "Platforms and Tools: Linux, Windows, AWS EC2 & S3, Visual Studio Code, Tableau, Git, DVC,  JIRA, Jenkins, VertexAI, Google Colab, Jupyter notebook, Streamlit.\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "MITx Micromasters in Statistics and Data Science (Online) \t\t\tMay 2024 to Nov 2025\n",
      "\n",
      "Scored 98% in Machine learning with Python course from MITx Micromasters Certificate.\n",
      "\n",
      "Scored 99% in  Probability - The Science of Uncertainty and Data  from MITx Micromasters Certificate.\n",
      "\n",
      "Sri Shakthi Institute Of Engineering and Technology (Anna University), Coimbatore \n",
      "\n",
      "Bachelors in  Electronics and Communication Engineering - 2014 - 2018 – Scored an overall CGPA of 8.44.\n",
      "\n",
      "COURSES AND CERTIFICATIONS\n",
      "\n",
      "Scored 98% in Machine learning with Python course from MITx Micromasters Certificate.\n",
      "\n",
      "Scored 99% in  Probability - The Science of Uncertainty and Data  from MITx Micromasters Certificate.\n",
      "\n",
      "Pursuing 2 other courses  from MITx Micromasters in Statistics and Data science bundle.\n",
      "\n",
      "GenAI Fundamentals from Google Cloud skills boost.\n",
      "\n",
      "Google Advanced Data Analytics Professional Certificate and Google Data Analytics Professional Certificate\n",
      "\n",
      "Detected customers increase in fraud when they are reaching us through a specific channel and added a channel-specific fraud model after customizing the dependent variable which reduced the fraud upto 10%. \n",
      "\n",
      "Model built to predicting External risk’s sensitivity using stratified sampling and propensity sample weighting for large dataset over 100K records. These models were built to be orthogonal to the existing ones.\n",
      "\n",
      "Created an automated model performance evaluation framework that evaluates the newly added models and also suggests how they perform well in addition to the existing ones. It also suggests the retirement of existing models when model drift happens. This framework reduced around 30% of the manual workload of the data scientists.\n",
      "\n",
      "Performed A/B, hypothesis tests and causal inference analysis to see if the reduction in risk is significant if a new rule is added in Underwriting. Proved that adding this new rule in Underwriting would cause a significant reduction in risk around 2% which was eventually put into production. Also wrote functions for Monte carlo simulation in a project where we simulated past customers to be in a present scenario.\n",
      "\n",
      "Worked cross-functionally  with the Machine Learning Engineering team, to give insights on ML algorithms and in developing modules and pipelines. Created a Jenkins automation pipeline for report generation using Python and groovy. \n",
      "\n",
      "Predicted the expected NPV with the current risk by building a model using the forecasted result and visualized using the Prediction and Confidence Intervals.\n",
      "\n",
      "Can make data-driven decisions by exploring, transforming and analyzing large loan data sets, by monitoring credit risk and default rates (PD, marginal bad rates and SMM) categorized by APRs and Pools using tableau. Created and Deployed datasources using RedShift tables to tableau using Tableau desktop version.\n",
      "Human: Give educational background of Haripriya Brief it in at most 35 words or the count limit given in the previous sentence.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'question': 'Give educational background of Haripriya Brief it in at most 35 words or the count limit given in the previous sentence.', 'chat_history': [], 'answer': \"Haripriya holds a Bachelor's degree in Electronics and Communication Engineering from Sri Shakthi Institute of Engineering and Technology, Coimbatore, with a CGPA of 8.44, and is pursuing a Micromasters in Statistics and Data Science.\"}\n"
     ]
    }
   ],
   "source": [
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm, retriever=configure_retriever(index_name), memory=memory, verbose=True,\n",
    "        combine_docs_chain_kwargs={\"prompt\": qa_prompt},\n",
    ")\n",
    "\n",
    "user_query = 'Give educational background of Haripriya'\n",
    "user_query += ' Brief it in at most 35 words or the count limit given in the previous sentence.'\n",
    "response = qa_chain.invoke({\"question\":user_query})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore Precision: 0.8738595843315125\n",
      "BERTScore Recall: 0.9114338159561157\n",
      "BERTScore F1: 0.8922513127326965\n"
     ]
    }
   ],
   "source": [
    "reference_texts = [['Haripriya had good scores in academics during school and studied Electronics and Communication Engineering. She also is studying micromasters in Statistics and Data science']]\n",
    "\n",
    "generated_texts = [\"Haripriya holds a Bachelor's degree in Electronics and Communication Engineering from Sri Shakthi Institute of Engineering and Technology, Coimbatore, with a CGPA of 8.44, and is pursuing a Micromasters in Statistics and Data Science.\"]\n",
    "\n",
    "bert_p, bert_r, bert_f1 = calculate_bertscore(generated_texts, reference_texts)\n",
    "print(f\"BERTScore Precision: {bert_p}\")\n",
    "print(f\"BERTScore Recall: {bert_r}\")\n",
    "print(f\"BERTScore F1: {bert_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better recall score and much better response as well. Earlier there was no information stating about my Engineering degree which I was expecting the most. Now it's better. We will try few other responses as well.\n",
    "\n",
    "As you can see, the context is of proper format which made this happen. Let's try the LLM evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contexts_for_testing\n",
    "contexts = contexts_for_testing.context_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1979, 1146, 1929, 1876]\n"
     ]
    }
   ],
   "source": [
    "print([len(context) for context in contexts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245b2a762c0f43fa9c684d6263920ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bdaefc7ac5d451d8419ba1b92f83128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contextualRecall :  1.0\n",
      "The score is 1.00 because the expected output aligns perfectly with the details from the nodes in the retrieval context, specifically mentioning 'Electronics and Communication Engineering' from node 9 and the 'micromasters in Statistics and Data Science' from node 1 under 'EDUCATION'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2def4bef8681447ba284b8d0a2925928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contextualRelevancy :  0.4186046511627907\n",
      "The score is 0.42 because while there are relevant educational achievements listed, such as 'Bachelors in Electronics and Communication Engineering - 2014 - 2018' and various certifications like 'Google Advanced Data Analytics Professional Certificate', the majority of the context focuses on job tasks and non-educational qualifications, as highlighted in the reasons for irrelevancy.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contextualPrecision :  0.5833333333333333\n",
      "The score is 0.58 because although there are relevant nodes that provide details about Haripriya's education, two irrelevant nodes rank higher than the last relevant one. Specifically, the first node detailing data preparation is ranked first and states, 'Performed Retro Data preparation and Analysis on new data products' which does not mention Haripriya's educational background. This lowers the score despite the presence of two relevant nodes ranked second and third, which effectively address her academic qualifications.\n"
     ]
    }
   ],
   "source": [
    "from deepeval.metrics import ContextualRecallMetric, ContextualRelevancyMetric, ContextualPrecisionMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "# Actual output from your LLM application\n",
    "actual_output = \"Haripriya Rajendran excelled academically, achieving school first in both SSLC and Higher Secondary with 97% marks, and district first in the Sri Ramanujan Maths aptitude test, alongside various professional certifications in data science and analytics.\"\n",
    "\n",
    "# Replace this with the expected output from your RAG generator\n",
    "expected_output = \"'Haripriya had good scores in academics during school and studied Electronics and Communication Engineering. She also is studying micromasters in Statistics and Data science'\"\n",
    "\n",
    "# Replace this with the actual retrieved context from your RAG pipeline\n",
    "retrieval_context = contexts\n",
    "\n",
    "contextualRecall = ContextualRecallMetric(\n",
    "    threshold=0.7,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    include_reason=True\n",
    ")\n",
    "test_case = LLMTestCase(\n",
    "    input=\"Give educational background of Haripriya\",\n",
    "    actual_output=actual_output,\n",
    "    expected_output=expected_output,\n",
    "    retrieval_context=retrieval_context\n",
    ")\n",
    "\n",
    "contextualRelevancy = ContextualRelevancyMetric(\n",
    "    threshold=0.7,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    include_reason=True\n",
    ")\n",
    "\n",
    "contextualPrecision = ContextualPrecisionMetric(\n",
    "    threshold=0.7,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    include_reason=True\n",
    ")\n",
    "\n",
    "contextualRecall.measure(test_case)\n",
    "print(\"contextualRecall : \", contextualRecall.score)\n",
    "print(contextualRecall.reason)\n",
    "\n",
    "contextualRelevancy.measure(test_case)\n",
    "print(\"contextualRelevancy : \", contextualRelevancy.score)\n",
    "print(contextualRelevancy.reason)\n",
    "\n",
    "contextualPrecision.measure(test_case)\n",
    "print(\"contextualPrecision : \", contextualPrecision.score)\n",
    "print(contextualPrecision.reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The contextual recall is the perfect score now that means atleast one of the contexts actually aligns with the expected output\n",
    "- The contextual relevancy is still low but better than previous because even though we have the context that we need, other contexts are not relevant to the input\n",
    "- The contexual precision is still low because there are relevant documents but is not ranked at the top. There is an irrelevant document at the top\n",
    "\n",
    "So far so good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test sample 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: give a summary on her GenerativeAI projects Brief it in at most 35 words or the count limit given in the previous sentence.\n",
      "Assistant: Haripriya worked on GenerativeAI using LLMs to automate NOAA decline translations, achieving 75% accuracy, and developed a channel-specific fraud model, enhancing fraud detection by 10% through customized dependent variable analysis.\n",
      "Follow Up Input: give a summary on her Generative AI projects Brief it in at most 35 words or the count limit given in the previous sentence.\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are A CHAT ASSISTANT even with or without context and you are NOT Haripriya. You are supposed to answer the questions asked only about Haripriya and you are NOT Haripriya. Use the following pieces of retrieved context to answer the question.\n",
      "\n",
      "Haripriya Rajendran\n",
      "\n",
      "Lead Data Scientist with GenerativeAI\n",
      "\n",
      "+1 279-245-9325\n",
      "\n",
      "California, United States\n",
      "\n",
      "haripriya04raj@gmail.com     \n",
      "\n",
      "linkedin.com/in/haripriyar             \n",
      "\n",
      "bit.ly/HpPortfolio                \n",
      "\n",
      "github.com/hari04hp\n",
      "\n",
      "Portfolio projects: \n",
      "\n",
      "https://github.com/hari04hp/my-portfolio \n",
      "\n",
      "https://github.com/hari04hp/langchain-weather-tool-calling\n",
      "\n",
      "\n",
      "\n",
      "PROFILE\n",
      "\n",
      "Data Scientist with over 7 years of overall experience with 5+  years of experience in Machine Learning, Data Analysis and Data Science in US based FinTech company. I also have 2 years of prior experience as a Software Developer. I have expertise in using GenAI models for RAG using LangChain, tool calling using Agents and fine tuning Gemma models.\n",
      "\n",
      "I have expertise in feature engineering, building models that predict US sub-prime consumers’ credit risk and fraud behaviours and in compiling a scorecard that works the best for increasing the profit and reducing risk.\n",
      "\n",
      "I trained myself in Data Science and Machine Learning through certified online courses, participated in ML hackathons and developed my skills.  Completed Google Advanced Data Analytics Professional certificate from coursera and scored 98% in two of the courses from MITx Micromasters. Pursuing other courses in the bundle as well. I am a ByteDance Innovator. Proficient in Python, RedShift, Tableau & MySQL. \n",
      "\n",
      "SKILLS\n",
      "\n",
      "Languages: Python (Preferred and expert), R(basics),  MySQL(expert), RedShift, MongoDB, BigQuery, [C#, Java, J2EE, PHP, Javascript](in the past role)\n",
      "\n",
      "SKILLS\n",
      "\n",
      "Languages: Python (Preferred and expert), R(basics),  MySQL(expert), RedShift, MongoDB, BigQuery, [C#, Java, J2EE, PHP, Javascript](in the past role)\n",
      "\n",
      "ML and DS algorithms and libraries: Pandas, Numpy, sklearn, gunicorn/Flask(REST APIs), joblib, seaborn, matplotlib, Regression, Random Forest, XGBoost, CatBoost, LightGBM,Ray, MLFlow, Optuna, TensorFlow, Keras PyTorch, PySpark, Data Mining, Data Extraction, Data Analytics, Feature Engineering, Machine learning Engineering, Model explainability, Predictive Modelling, Exploratory Data Analysis, Statistical Analysis, Hypothesis testing, A/B testing, Deep Learning, K-Means, Recommendation systems, Reinforcement Learning, Clustering, Expectation Maximization Algorithm, NLP, GenerativeAI, LangChain, OpenAI, RAG, LLMs, Prompt Engineering, Function Calling/Tool Calling.\n",
      "\n",
      "Platforms and Tools: Linux, Windows, AWS EC2 & S3, Visual Studio Code, Tableau, Git, DVC,  JIRA, Jenkins, VertexAI, Google Colab, Jupyter notebook, Streamlit.\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "MITx Micromasters in Statistics and Data Science (Online) \t\t\tMay 2024 to Nov 2025\n",
      "\n",
      "Scored 98% in Machine learning with Python course from MITx Micromasters Certificate.\n",
      "\n",
      "Scored 99% in  Probability - The Science of Uncertainty and Data  from MITx Micromasters Certificate.\n",
      "\n",
      "Sri Shakthi Institute Of Engineering and Technology (Anna University), Coimbatore \n",
      "\n",
      "Bachelors in  Electronics and Communication Engineering - 2014 - 2018 – Scored an overall CGPA of 8.44.\n",
      "\n",
      "COURSES AND CERTIFICATIONS\n",
      "\n",
      "Scored 98% in Machine learning with Python course from MITx Micromasters Certificate.\n",
      "\n",
      "Scored 99% in  Probability - The Science of Uncertainty and Data  from MITx Micromasters Certificate.\n",
      "\n",
      "Pursuing 2 other courses  from MITx Micromasters in Statistics and Data science bundle.\n",
      "\n",
      "GenAI Fundamentals from Google Cloud skills boost.\n",
      "\n",
      "Google Advanced Data Analytics Professional Certificate and Google Data Analytics Professional Certificate\n",
      "\n",
      "Detected customers increase in fraud when they are reaching us through a specific channel and added a channel-specific fraud model after customizing the dependent variable which reduced the fraud upto 10%. \n",
      "\n",
      "Model built to predicting External risk’s sensitivity using stratified sampling and propensity sample weighting for large dataset over 100K records. These models were built to be orthogonal to the existing ones.\n",
      "\n",
      "Created an automated model performance evaluation framework that evaluates the newly added models and also suggests how they perform well in addition to the existing ones. It also suggests the retirement of existing models when model drift happens. This framework reduced around 30% of the manual workload of the data scientists.\n",
      "\n",
      "Performed A/B, hypothesis tests and causal inference analysis to see if the reduction in risk is significant if a new rule is added in Underwriting. Proved that adding this new rule in Underwriting would cause a significant reduction in risk around 2% which was eventually put into production. Also wrote functions for Monte carlo simulation in a project where we simulated past customers to be in a present scenario.\n",
      "\n",
      "Worked cross-functionally  with the Machine Learning Engineering team, to give insights on ML algorithms and in developing modules and pipelines. Created a Jenkins automation pipeline for report generation using Python and groovy. \n",
      "\n",
      "Predicted the expected NPV with the current risk by building a model using the forecasted result and visualized using the Prediction and Confidence Intervals.\n",
      "\n",
      "Can make data-driven decisions by exploring, transforming and analyzing large loan data sets, by monitoring credit risk and default rates (PD, marginal bad rates and SMM) categorized by APRs and Pools using tableau. Created and Deployed datasources using RedShift tables to tableau using Tableau desktop version.\n",
      "\n",
      "Micromasters ML with python Certificate: https://courses.edx.org/certificates/0bb4d2a3afaf4084b9769e38fe2e3621\n",
      "\n",
      "Google Advanced Data Analytics Professional Certificate : https://coursera.org/share/834777bcafebf5b786b8ccf9bfec2310\n",
      "\n",
      "Google Data Analytics Professional Certificate : https://coursera.org/share/a6cbcd753c518c0fa1e1963280ab8837\n",
      "\n",
      "Udemy ML certificate: https://www.udemy.com/certificate/UC-AFTSGUV3/\n",
      "\n",
      "GenAI Fundamentals from Google Cloud skills boost : https://www.cloudskillsboost.google/public_profiles/cbdc244d-9d0c-47d9-97cf-9df0f2ce0b34/badges/8137055\n",
      "\n",
      "“Machine Learning” - Stanford University - Coursera Certificate : https://coursera.org/share/3abf0fbf2896aab2351dd1b0f6a15e2f\n",
      "\n",
      "Programming for Everybody (Python)- U-M - Coursera Certificate : https://coursera.org/share/82e42e01b306f5a268181bb5267246c1\n",
      "\n",
      "MITx Micromasters: https://micromasters.mit.edu/ds/\n",
      "\n",
      "Kaggle Page : https://www.kaggle.com/haripriya04raj\n",
      "\n",
      "MachineHack : https://machinehack.com/user/5ef0a238b7efcc325e3907d1\n",
      "\n",
      "Case Study in RPubs: https://rpubs.com/haripriya_rhp/cyclistic-case-study\n",
      "\n",
      "Case Study in GitHub : https://github.com/hari04hp/google-advanced-capstone\n",
      "Human: Can you provide a summary of her Generative AI projects in no more than 35 words?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'question': 'give a summary on her Generative AI projects Brief it in at most 35 words or the count limit given in the previous sentence.', 'chat_history': [HumanMessage(content='give a summary on her GenerativeAI projects Brief it in at most 35 words or the count limit given in the previous sentence.', additional_kwargs={}, response_metadata={}), AIMessage(content='Haripriya worked on GenerativeAI using LLMs to automate NOAA decline translations, achieving 75% accuracy, and developed a channel-specific fraud model, enhancing fraud detection by 10% through customized dependent variable analysis.', additional_kwargs={}, response_metadata={})], 'answer': 'Haripriya specializes in Generative AI, utilizing LangChain for RAG, tool calling with Agents, and fine-tuning Gemma models, enhancing predictive capabilities and automating processes in data science applications.'}\n"
     ]
    }
   ],
   "source": [
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm, retriever=configure_retriever(index_name), memory=memory, verbose=True,\n",
    "        combine_docs_chain_kwargs={\"prompt\": qa_prompt},\n",
    ")\n",
    "\n",
    "user_query = 'give a summary on her Generative AI projects'\n",
    "user_query += ' Brief it in at most 35 words or the count limit given in the previous sentence.'\n",
    "response = qa_chain.invoke({\"question\":user_query})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore Precision: 0.8725282549858093\n",
      "BERTScore Recall: 0.874882698059082\n",
      "BERTScore F1: 0.8737038373947144\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "reference_texts = [['Haripriya has worked on her portfolio project on creating a chat assistant about her using RAG with generativeAI and langchain. She also has created a weather API agent using streamlit']]\n",
    "\n",
    "generated_texts = [\"Haripriya specializes in Generative AI, utilizing LangChain for RAG, tool calling with Agents, and fine-tuning Gemma models, enhancing predictive capabilities and automating processes in data science applications.\"]\n",
    "\n",
    "bert_p, bert_r, bert_f1 = calculate_bertscore(generated_texts, reference_texts)\n",
    "print(f\"BERTScore Precision: {bert_p}\")\n",
    "print(f\"BERTScore Recall: {bert_r}\")\n",
    "print(f\"BERTScore F1: {bert_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1509, 1929, 1876, 1146]\n"
     ]
    }
   ],
   "source": [
    "import contexts_for_testing\n",
    "contexts = contexts_for_testing.context_3\n",
    "print([len(context) for context in contexts])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706bcf1188984c7e81745a85f86b1b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48dcea6fa54e4ae2810fc8e607674829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contextualRecall :  1.0\n",
      "The score is 1.00 because all elements of the expected output perfectly align with the provided context nodes, with the chat assistant work linking to node 5 and the weather API creation linked to node 1.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e9cb387f5a49e797e3a0a2ecda3ff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contextualRelevancy :  0.12903225806451613\n",
      "The score is 0.13 because, despite the presence of relevant statements like 'Lead Data Scientist with GenerativeAI' and 'expertise in using GenAI models,' the majority of the context focuses on unrelated qualifications and general skills rather than summarizing specific Generative AI projects.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contextualPrecision :  1.0\n",
      "The score is 1.00 because all relevant nodes are ranked higher than the irrelevant nodes. The first node highlights expertise in 'using GenAI models for RAG using LangChain', making it directly pertinent to Generative AI projects. Similarly, the second node presents a specific Generative AI portfolio project, the 'langchain-weather-tool-calling'. In contrast, the third and fourth nodes discuss themes unrelated to Generative AI, such as model performance evaluation and course certifications, allowing for a clear distinction in relevance.\n"
     ]
    }
   ],
   "source": [
    "from deepeval.metrics import ContextualRecallMetric, ContextualRelevancyMetric, ContextualPrecisionMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "# Actual output from your LLM application\n",
    "actual_output = \"Haripriya specializes in Generative AI, utilizing LangChain for RAG, tool calling with Agents, and fine-tuning Gemma models, enhancing predictive capabilities and automating processes in data science applications.\"\n",
    "\n",
    "# Replace this with the expected output from your RAG generator\n",
    "expected_output = 'Haripriya has worked on her portfolio project on creating a chat assistant about her using RAG with generativeAI and langchain. She also has created a weather API agent using streamlit'\n",
    "\n",
    "# Replace this with the actual retrieved context from your RAG pipeline\n",
    "retrieval_context = contexts\n",
    "\n",
    "contextualRecall = ContextualRecallMetric(\n",
    "    threshold=0.7,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    include_reason=True\n",
    ")\n",
    "test_case = LLMTestCase(\n",
    "    input=\"give a summary on her Generative AI projects\",\n",
    "    actual_output=actual_output,\n",
    "    expected_output=expected_output,\n",
    "    retrieval_context=retrieval_context\n",
    ")\n",
    "\n",
    "contextualRelevancy = ContextualRelevancyMetric(\n",
    "    threshold=0.7,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    include_reason=True\n",
    ")\n",
    "\n",
    "contextualPrecision = ContextualPrecisionMetric(\n",
    "    threshold=0.7,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    include_reason=True\n",
    ")\n",
    "\n",
    "contextualRecall.measure(test_case)\n",
    "print(\"contextualRecall : \", contextualRecall.score)\n",
    "print(contextualRecall.reason)\n",
    "\n",
    "contextualRelevancy.measure(test_case)\n",
    "print(\"contextualRelevancy : \", contextualRelevancy.score)\n",
    "print(contextualRelevancy.reason)\n",
    "\n",
    "contextualPrecision.measure(test_case)\n",
    "print(\"contextualPrecision : \", contextualPrecision.score)\n",
    "print(contextualPrecision.reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The contextual recall is the perfect score now that means atleast one of the contexts actually aligns with the expected output\n",
    "- The contextual relevancy is very low because even though we have the context that we need, other contexts are not relevant to the input\n",
    "- The contexual precision is still low because there are relevant documents but is not ranked at the top. There is an irrelevant document at the top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot increase contextual relevancy for now, but increasing contextual recall was the major goal and we achieved it! I would consider this as a success, atleast for this project!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
